{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P3_jaccard_cosine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Jaccard's Coefficient"
      ],
      "metadata": {
        "id": "KRE1nZih41Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PAWdkPM4Kn0",
        "outputId": "bc8582c1-4477-427f-cded-b6d0a7cc88d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = \"Data is the new oil of the digital economy.\"\n",
        "doc2 = \"Data is a new oil.\"\n",
        "\n",
        "# Split the documents and create tokens\n",
        "doc1_tokens=set(doc1.lower().split())\n",
        "doc2_tokens=set(doc2.lower().split())\n",
        "\n",
        "#Print the tokens\n",
        "print(doc1_tokens,doc2_tokens)"
      ],
      "metadata": {
        "id": "HcjJg8BnNudM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c5e850-be4e-47ac-e586-a292e50715e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the', 'is', 'economy.', 'oil', 'data', 'digital', 'new', 'of'} {'is', 'a', 'data', 'oil.', 'new'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Jaccard Similarity\n",
        "jaccard_similarity=  len(doc1_tokens.intersection(doc2_tokens))/len(doc1_tokens.union(doc2_tokens))\n",
        "\n",
        "# Print the Jaccard Simialrity score\n",
        "print(jaccard_similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dXoaAsxhM9A",
        "outputId": "a531e1f0-a5cc-4209-d301-48d6776d9b38"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cosine similarity"
      ],
      "metadata": {
        "id": "PLvqSTSG6UK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's import text feature extraction TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Import Cosien Similarity metric\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "XHnHDjRNt_CL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs=['Data is the oil of the digital economy.', 'Data is a new oil.']\n",
        "\n",
        "# Create TFidfVectorizer \n",
        "tfidf= TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents \n",
        "tfidf_vector = tfidf.fit_transform(docs)\n",
        "\n",
        "# Compute cosine similarity\n",
        "cosine_sim=cosine_similarity(tfidf_vector, tfidf_vector)\n",
        "\n",
        "# Print the cosine similarity\n",
        "print(cosine_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVRvqSwIgwS0",
        "outputId": "d7964ec4-0cd6-427c-d702-4c27f3724199"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.32787075]\n",
            " [0.32787075 1.        ]]\n"
          ]
        }
      ]
    }
  ]
}